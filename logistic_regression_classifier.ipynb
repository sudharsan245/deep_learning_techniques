{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3699169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100/5000, Cost: 0.5478\n",
      "Iteration 200/5000, Cost: 0.4618\n",
      "Iteration 300/5000, Cost: 0.4058\n",
      "Iteration 400/5000, Cost: 0.3662\n",
      "Iteration 500/5000, Cost: 0.3366\n",
      "Iteration 600/5000, Cost: 0.3135\n",
      "Iteration 700/5000, Cost: 0.2948\n",
      "Iteration 800/5000, Cost: 0.2793\n",
      "Iteration 900/5000, Cost: 0.2662\n",
      "Iteration 1000/5000, Cost: 0.2550\n",
      "Iteration 1100/5000, Cost: 0.2452\n",
      "Iteration 1200/5000, Cost: 0.2366\n",
      "Iteration 1300/5000, Cost: 0.2290\n",
      "Iteration 1400/5000, Cost: 0.2221\n",
      "Iteration 1500/5000, Cost: 0.2159\n",
      "Iteration 1600/5000, Cost: 0.2103\n",
      "Iteration 1700/5000, Cost: 0.2052\n",
      "Iteration 1800/5000, Cost: 0.2004\n",
      "Iteration 1900/5000, Cost: 0.1961\n",
      "Iteration 2000/5000, Cost: 0.1921\n",
      "Iteration 2100/5000, Cost: 0.1883\n",
      "Iteration 2200/5000, Cost: 0.1848\n",
      "Iteration 2300/5000, Cost: 0.1816\n",
      "Iteration 2400/5000, Cost: 0.1785\n",
      "Iteration 2500/5000, Cost: 0.1757\n",
      "Iteration 2600/5000, Cost: 0.1730\n",
      "Iteration 2700/5000, Cost: 0.1704\n",
      "Iteration 2800/5000, Cost: 0.1680\n",
      "Iteration 2900/5000, Cost: 0.1657\n",
      "Iteration 3000/5000, Cost: 0.1635\n",
      "Iteration 3100/5000, Cost: 0.1615\n",
      "Iteration 3200/5000, Cost: 0.1595\n",
      "Iteration 3300/5000, Cost: 0.1576\n",
      "Iteration 3400/5000, Cost: 0.1559\n",
      "Iteration 3500/5000, Cost: 0.1542\n",
      "Iteration 3600/5000, Cost: 0.1525\n",
      "Iteration 3700/5000, Cost: 0.1509\n",
      "Iteration 3800/5000, Cost: 0.1494\n",
      "Iteration 3900/5000, Cost: 0.1480\n",
      "Iteration 4000/5000, Cost: 0.1466\n",
      "Iteration 4100/5000, Cost: 0.1453\n",
      "Iteration 4200/5000, Cost: 0.1440\n",
      "Iteration 4300/5000, Cost: 0.1427\n",
      "Iteration 4400/5000, Cost: 0.1415\n",
      "Iteration 4500/5000, Cost: 0.1404\n",
      "Iteration 4600/5000, Cost: 0.1393\n",
      "Iteration 4700/5000, Cost: 0.1382\n",
      "Iteration 4800/5000, Cost: 0.1371\n",
      "Iteration 4900/5000, Cost: 0.1361\n",
      "Iteration 5000/5000, Cost: 0.1351\n",
      "\n",
      "Model Accuracy on Test Set: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.metrics import accuracy_score \n",
    "# 1. Load dataset (using breast cancer dataset for demonstration) \n",
    "X, y = load_breast_cancer(return_X_y=True) \n",
    "# Split the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "# 2. Normalize the data (a simple standardization) \n",
    "# Avoid dividing by zero if std is 0 \n",
    "X_train = (X_train - np.mean(X_train, axis=0)) / (np.std(X_train, axis=0) + 1e-8) \n",
    "X_test = (X_test - np.mean(X_test, axis=0)) / (np.std(X_test, axis=0) + 1e-8) \n",
    "class LogisticRegressionModel: \n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000): \n",
    "        self.learning_rate = learning_rate \n",
    "        self.num_iterations = num_iterations \n",
    "        self.weights = None \n",
    "        self.bias = None \n",
    "# 4. Implement forward propagation using sigmoid activation. \n",
    "    def _sigmoid(self, z): \n",
    "        return 1 / (1 + np.exp(-z)) \n",
    "    # 3. Initialize parameters (weights and bias). \n",
    "    def fit(self, X, y): \n",
    "        n_samples, n_features = X.shape \n",
    "        self.weights = np.zeros(n_features) \n",
    "        self.bias = 0 \n",
    "        # 6. Perform gradient descent (backward propagation). \n",
    "        for iteration in range(self.num_iterations): \n",
    "            # Forward pass \n",
    "            linear_model = np.dot(X, self.weights) + self.bias \n",
    "            y_predicted = self._sigmoid(linear_model) \n",
    "            # 5. Compute cost (Binary Cross-Entropy) \n",
    "            # Adding a small value (1e-8) to prevent log(0) \n",
    "            cost = -np.mean(y * np.log(y_predicted + 1e-8) + (1 - y) * np.log(1 - y_predicted + 1e-8)) \n",
    "            # Backpropagation \n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_predicted - y)) \n",
    "            db = (1/n_samples) * np.sum(y_predicted - y) \n",
    "            # Update parameters \n",
    "            self.weights -= self.learning_rate * dw \n",
    "            self.bias -= self.learning_rate * db \n",
    "            # Print cost every 100 iterations \n",
    "            if (iteration+1) % 100 == 0: \n",
    "                print(f\"Iteration {iteration+1}/{self.num_iterations}, Cost: {cost:.4f}\") \n",
    "    # 7. Predict and evaluate model performance. \n",
    "    def predict(self, X): \n",
    "        linear_model = np.dot(X, self.weights) + self.bias \n",
    "        y_predicted = self._sigmoid(linear_model) \n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted] \n",
    "        return np.array(y_predicted_cls) \n",
    "# Instantiate and train the custom model \n",
    "lr_model = LogisticRegressionModel(learning_rate=0.001, num_iterations=5000) \n",
    "lr_model.fit(X_train, y_train) \n",
    "# Predict on the test set \n",
    "y_pred = lr_model.predict(X_test) \n",
    "# Evaluate performance \n",
    "accuracy = accuracy_score(y_test, y_pred) \n",
    "print(\"\\nModel Accuracy on Test Set:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
